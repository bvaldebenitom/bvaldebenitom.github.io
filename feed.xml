<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://bvaldebenitom.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://bvaldebenitom.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-03-09T14:42:44+00:00</updated><id>https://bvaldebenitom.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Nextflow_vs_snakemake</title><link href="https://bvaldebenitom.github.io/blog/2024/nextflow_vs_snakemake/" rel="alternate" type="text/html" title="Nextflow_vs_snakemake"/><published>2024-03-06T00:00:00+00:00</published><updated>2024-03-06T00:00:00+00:00</updated><id>https://bvaldebenitom.github.io/blog/2024/nextflow_vs_snakemake</id><content type="html" xml:base="https://bvaldebenitom.github.io/blog/2024/nextflow_vs_snakemake/"><![CDATA[<p>– layout: post title: ** date: 2024-03-06 05:55:00 description: ** tags: workflows rnaseq categories: reviews thumbnail: assets/img/PENDING_thumbnail.png toc: beginning: true —</p> <h2 id="introduction">Introduction</h2> <p>Throughout my career, I have always enjoyed the development of pipelines as a mean to efficiently process hundreds of files efficiently. I usually do this directly on Bash, as these pipelines connect the inputs and outputs of different software. I have been able to publish some of these tools in several journals, and at this point I’m always wondering whether they will work in all environments for all users. Although I have made a conscious effort to make them reproducible, they still fail at some point. Another issue is with Bash pipelines, is that I always have to make blocks of “if-else” statements just to check whether the inputs and outputs were created, which is very cumbersome.</p> <p>During the last 2 years, I have come across Nextflow and Snakemake, which both seem to have the aim to provide an infrastructure for “reproducible and scalable” workflows. In early 2023 I started using Snakemake, and in practice it effectively seemed to provide a cleaner and more organized way to develop and run pipelines. In particular, if you need to run different tools that need their own Conda environment, with Snakemake you can seamlessly define such environments and it will automatically switch them accordingly at execution time. This, however, also seems to be one of its drawbacks as it needs Conda to do so, and this can take ages some times (the always there “Solving environment”.. Just type “conda so” in Google and you will see that the most searched phrase is related to this). Though there is a way to make it run with Mamba, which is faster, it can get confusing if you haven’t work with Python and Conda environments before. On the other hand, Nextflow, as we will see later, seems simpler, and it doesn’t require jumping into the whole snakes universe of Conda-Mamba-Snakemake.</p> <p>To get more familiarized with both Nextflow and Snakemake, I adapted a simplified version of my RNA-Seq workflow from scratch to each of these frameworks. In this post I will be discussing some of my findings and what I would recommend for someone wanting to implement them.</p> <h2 id="the-workflow">The workflow</h2> <p>For this workflow, I simulated reads in FASTQ formats: 3 paired-end libraries and 1 single-end library. Then, these reads would need to be quality checked with FastQC, aligned against the human genome with STAR, and finally, processed with Telescope to get expression estimates for Transposable Elements (Figure 1).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/02_nextflow_vs_snakemake/figure01-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/02_nextflow_vs_snakemake/figure01-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/02_nextflow_vs_snakemake/figure01-1400.webp"/> <img src="/assets/img/02_nextflow_vs_snakemake/figure01.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>There are 2 considerations for the pipeline:</p> <ol> <li>It should automatically detect whether the libraries are single-end or paired-end.</li> <li>Telescope needs to be run on its own Conda environment (I have already built it), so it should be able to reuse the same existing environment.</li> </ol> <p>I will show the implementation first on Snakemake and latter on Nextflow.</p> <h3 id="snakemake-implementation">Snakemake implementation</h3> <h4 id="setup">Setup</h4>]]></content><author><name></name></author><summary type="html"><![CDATA[– layout: post title: ** date: 2024-03-06 05:55:00 description: ** tags: workflows rnaseq categories: reviews thumbnail: assets/img/PENDING_thumbnail.png toc: beginning: true —]]></summary></entry><entry><title type="html">Automatization of IGV snapshots</title><link href="https://bvaldebenitom.github.io/blog/2024/igv_coverage/" rel="alternate" type="text/html" title="Automatization of IGV snapshots"/><published>2024-01-06T09:40:00+00:00</published><updated>2024-01-06T09:40:00+00:00</updated><id>https://bvaldebenitom.github.io/blog/2024/igv_coverage</id><content type="html" xml:base="https://bvaldebenitom.github.io/blog/2024/igv_coverage/"><![CDATA[<p>Ever since I started analyzing Transposable Elements (TEs) expression in RNA-Seq data, I have been curious to see the genomic coverage of specific loci. Moreover, when I found out that <a href="https://academic.oup.com/nar/article/47/5/e27/5280934">SQuIRE</a>, one of the best tools at the moment, could generate thousands of false positives, I was more aware of the need to manually verify the expression of TEs. Since there was a large amount of loci to check, I would always postpone this task, as I was never able to find an automated way of generating genomic coverage snapshots. Instead, after several statistical analyses, I would try to shorten the list of TEs to the smallest amount possible, so I could later check them one-by-one on the Integrative Genomics Viewer (IGV) application.</p> <p>It wasn’t until a few weeks ago that I decided to attempt this again. In turn, I was able to find this <a href="https://janbio.home.blog/2020/09/16/igv-batch-snapshot-from-command-line/">blog post</a> with the backbone of the solution. Since then, I modified it to suit my needs for RNA-Seq analyses, and decided to write this post as a more definite tutorial that goes from scratch to the final generation of these long-coveted automated IGV snapshots.</p> <h4 id="1-what-you-will-need">1. What you will need</h4> <ul> <li>Command line IGV 2.16.2 (https://igv.org/)</li> <li>Samtools (https://www.htslib.org/)</li> <li>A genome FASTA file (for this tutorial, I'm using the mm10 FASTA <a href="https://hgdownload.soe.ucsc.edu/goldenPath/mm10/bigZips/">from UCSC</a>)</li> <li>A GTF file (for this tutorial, I'm using the mm10 NCBI RefSeq <a href="https://hgdownload.soe.ucsc.edu/goldenPath/mm10/bigZips/genes/">from UCSC</a>)</li> <li>One or more BAM files (I'm using 2 BAM files here)</li> </ul> <h4 id="2-generating-the-snapshots">2. Generating the snapshots</h4> <p>There are two main steps to actually generating the IGV snapshots in an automated manner. First, we need to index the genome FASTA file, the genome annotation GTF file, and the BAM files.</p> <p>To make things simpler, I recommend creating an environment variable that contains the path to the IGV command line directory:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>export IGV_HOME=/path/IGV_2.16.2/
</code></pre></div></div> <p>Then, to index the genome FASTA file, we can do it like this:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$IGV_HOME/igvtools index mm10.fa
</code></pre></div></div> <p>For the GTF file, we need to sort it first, and then we can run the index command:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$IGV_HOME/igvtools sort mm10.ncbiRefSeq.gtf mm10.ncbiRefSeq_sorted.gtf
$IGV_HOME/igvtools index mm10.ncbiRefSeq_sorted.gtf
</code></pre></div></div> <p><strong>WARNING</strong>: Failure to index the GTF file, will result in long running times. Although the snapshot commands will work, when testing this tutorial on the unindexed file, it went for more than 26 minutes when loading it versus the ~1 minute it will take with the sorted and indexed version.</p> <p>Finally, to index the BAM files, we can use samtools:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>samtools index W8S1PA_Aligned.sortedByCoord.out.bam
samtools index W8S3SM_Aligned.sortedByCoord.out.bam
</code></pre></div></div> <p>The second step is creating the IGV script that will be used to actually generate the snapshots. Here is the template I use now:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gh">#load files</span>
genome mm10.fa 
load mm10.ncbiRefSeq_sorted.gtf 
 
preference SAM.SHOW_ALIGNMENT_TRACK false 

load W8S3SM_Aligned.sortedByCoord.out.bam 
load W8S1PA_Aligned.sortedByCoord.out.bam 
 
<span class="gh">#create snapshots </span>
snapshotDirectory . 

goto chr3:83,764,321-83,776,316 
snapshot igv_demo_sfrp2.png 
 
exit 
</code></pre></div></div> <p>We can save this into the file <code class="language-plaintext highlighter-rouge">igv_snapshot_demo.batch</code>. The script basically consists of loading the genome files (FASTA and sorted GTF), then setting <code class="language-plaintext highlighter-rouge">SAM.SHOW_ALIGNMENT_TRACK</code> to <code class="language-plaintext highlighter-rouge">false</code>, as I don’t usually need to check the reads track, and loading the BAM files. Later, we define the snapshot directory, and through the <code class="language-plaintext highlighter-rouge">goto</code> and <code class="language-plaintext highlighter-rouge">snapshot</code> commands we are actually creating them.</p> <p>Once all the above is done, we can run this final command to efficiently generate all the snapshots in one go:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>xvfb-run --auto-servernum --server-num=1 java -showversion --module-path="${IGV_HOME}/lib" -Xmx8g @"${IGV_HOME}/igv.args" --module=org.igv/org.broad.igv.ui.Main -b igv_snapshot_demo.batch
</code></pre></div></div> <p>In this example, the generated snapshot will be:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/igv_tutorial_sfrp2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/igv_tutorial_sfrp2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/igv_tutorial_sfrp2-1400.webp"/> <img src="/assets/img/igv_tutorial_sfrp2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Snapshot generated for the Sfrp2 gene using the commands in this tutorial. </div> <p>With this, we can now finally generate snapshots for a large number of genomic locations in an automated manner!</p>]]></content><author><name></name></author><category term="tutorials"/><category term="rnaseq"/><summary type="html"><![CDATA[A tutorial on best practices and how to do command line automatization of genomic coverage snapshots using the Integrative Genomics Viewer]]></summary></entry></feed>